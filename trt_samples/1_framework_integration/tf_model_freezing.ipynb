{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Checkpoint file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample code will show how to freeze tensorflow snapshot using tensorflow model_freezing tool. The snapshot files are slim based files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ckpt='snapshots'\n",
    "path_frozen_models='frozen_models'\n",
    "\n",
    "if (os.path.exists(path_ckpt) is False):\n",
    "    os.mkdir(path_ckpt)\n",
    "if (os.path.exists(path_frozen_models) is False):\n",
    "    os.mkdir(path_frozen_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put tensorflow snapshot files as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link='http://download.tensorflow.org/models'\n",
    "ls_model_file=[\n",
    "        'inception_v3_2016_08_28.tar.gz',\n",
    "        'resnet_v1_50_2016_08_28.tar.gz',\n",
    "        'resnet_v2_50_2017_04_14.tar.gz',\n",
    "        'mobilenet_v1_0.50_160_2017_06_14.tar.gz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tensorflow snapshot files and untar them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading inception_v3_2016_08_28.tar.gz ...  used already exist!!\n",
      "Downloading resnet_v1_50_2016_08_28.tar.gz ...  used already exist!!\n",
      "Downloading resnet_v2_50_2017_04_14.tar.gz ...  used already exist!!\n",
      "Downloading mobilenet_v1_0.50_160_2017_06_14.tar.gz ...  used already exist!!\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "def download_ckpt(link, ls_model):\n",
    "    for model in ls_model:\n",
    "        link_ = os.path.join(link, model)\n",
    "        print('Downloading', model, '...  ', end=\"\")\n",
    "        if (os.path.exists(os.path.join(path_ckpt, model)) is False):\n",
    "            wget.download(link_, out=os.path.join(path_ckpt, model))\n",
    "            print('done')\n",
    "        else:\n",
    "            print('used already exist!!')\n",
    "        \n",
    "download_ckpt(link, ls_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_v3.. already exist!!\n",
      "resnet_v1_50.. already exist!!\n",
      "resnet_v2_50.. already exist!!\n",
      "mobilenet_v1_0.. already exist!!\n"
     ]
    }
   ],
   "source": [
    "import tarfile,sys\n",
    "\n",
    "def untar_ckpt(fname):\n",
    "    with tarfile.open(fname) as tar:\n",
    "        model_name = [file for file in tar.getnames() if \"ckpt\" in file][0].split('.')[0]\n",
    "        print(model_name, end='')\n",
    "        if (os.path.exists(os.path.join(path_ckpt, model_name)) is False):\n",
    "            tar.extractall(os.path.join(path_ckpt, model_name))\n",
    "            print('.. done')\n",
    "        else:\n",
    "            print('.. already exist!!')\n",
    "    return model_name\n",
    "            \n",
    "ls_model = []\n",
    "for model_file in ls_model_file:\n",
    "    model = untar_ckpt(os.path.join('./', path_ckpt, model_file))\n",
    "    ls_model.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tensorflow  & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "from tensorflow.python.training import saver as saver_lib\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using slim model, we need to get slim graph from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed that tensorflow models directory existance\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists('models') is False):\n",
    "    os.system('git clone -b 2d7a0d6abba764b768d645947014492ade492385 https://github.com/tensorflow/models')\n",
    "else:\n",
    "    print('Confirmed that tensorflow models directory existance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.research.slim.nets import nets_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is resnet_v2_50\n"
     ]
    }
   ],
   "source": [
    "model_name = ls_model[2]\n",
    "print(\"Selected model is\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphdef_file = os.path.join(path_ckpt, model_name, model_name + '_graph.pb')\n",
    "checkpoint_path = os.path.join(path_ckpt, model_name)\n",
    "frozenmodel_path = os.path.join(path_ckpt, model_name, model_name + '_frozen.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we export graphdef file to get graph's output layer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: resnet_v2_50\n",
      "Graph path: snapshots/resnet_v2_50/resnet_v2_50_graph.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jahan/2_tftrt/models/research/slim/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$model_name\" \"$graphdef_file\"\n",
    "echo \"Model name: $1\"\n",
    "echo \"Graph path: $2\"\n",
    "python models/research/slim/export_inference_graph.py \\\n",
    "    --model_name=$1 \\\n",
    "    --output_file=$2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/jahan/.local/lib/python3.5/site-packages/slim-0.1-py3.5.egg/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "output_layer: resnet_v2_50/predictions/Reshape_1\n"
     ]
    }
   ],
   "source": [
    "graphdef_file = os.path.join(path_ckpt, model_name, model_name + '_graph.pbtxt')\n",
    "with tf.Graph().as_default() as graph:\n",
    "    network_fn = nets_factory.get_network_fn(\n",
    "        model_name,\n",
    "        num_classes=1001,\n",
    "        is_training=False\n",
    "    )\n",
    "    image_size = network_fn.default_image_size\n",
    "    inputs = tf.random_uniform((8, image_size, image_size, 3))\n",
    "    logits, end_points = network_fn(inputs)\n",
    "    out_layer = list(end_points.items())[-1][1].name.split(':')[0]\n",
    "    print('output_layer:', out_layer)\n",
    "    \n",
    "    # remove nodes not needed for inference from graph def\n",
    "    inference_graph = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "    \n",
    "    # write the graph definition to a file\n",
    "    graph_io.write_graph(inference_graph, '.', graphdef_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result files are;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:\t\t resnet_v2_50\n",
      "Output Layer:\t\t resnet_v2_50/predictions/Reshape_1\n",
      "Model's Graphdef file:\t snapshots/resnet_v2_50/resnet_v2_50_graph.pbtxt\n",
      "Frozen model file's path: snapshots/resnet_v2_50/resnet_v2_50_frozen.pb\n",
      "Source ckpt file path:\t snapshots/resnet_v2_50/resnet_v2_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Name:\\t\\t\", model_name)\n",
    "print(\"Output Layer:\\t\\t\", out_layer)\n",
    "print(\"Model's Graphdef file:\\t\", graphdef_file)\n",
    "print(\"Frozen model file's path:\", frozenmodel_path)\n",
    "print(\"Source ckpt file path:\\t\", os.path.join(path_ckpt, model_name, model_name + '.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Freesing\n",
    "Finally, we uses tensorflow's freeze_graph tool. It is possible that some checkpoints files cannot be freezed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from snapshots/resnet_v2_50/resnet_v2_50.ckpt\n",
      "INFO:tensorflow:Froze 272 variables.\n",
      "Converted 272 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph.freeze_graph(\n",
    "    input_graph=graphdef_file,\n",
    "    input_checkpoint=os.path.join(path_ckpt, model_name, model_name + '.ckpt'),\n",
    "    input_binary=False,\n",
    "    output_graph=frozenmodel_path,\n",
    "    output_node_names=out_layer,\n",
    "    input_saver=\"\",\n",
    "    restore_op_name=\"save/restore_all\",\n",
    "    filename_tensor_name=\"save/Const:0\",\n",
    "    clear_devices=True,\n",
    "    initializer_nodes=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
