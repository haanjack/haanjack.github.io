---
layout: post
title:  "APEX를 활용한 PyTorch 가속"
description: "TensorCore 또는 Volta를 활용하여 Deep Learning 가속"
date:   2018-6-27
published: false
categories: Deep Learning
tags:
 - nvidia
 - GPU
 - PyTorch
---

안녕하세요.

이번에 CVPR에서 NVIDIA가 발표한 것 중 APEX(A PyTorch Extension: https://github.com/NVIDIA/apex)를 소개해 드릴려고 합니다. 며칠 전에 같은 그룹에 계신 분이 소개를 해주셔서 중복이긴 한데 괜찮겠죠..?

Lecun 교수님이야 짧게 소개만 하시면 되셨겠지만...
https://twitter.com/ylecun/status/1009333331295686656

APEX는 Mixed-precision training(https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)을 쉽게 사용하실 수 있도록 만들어진 Library입니다. PyTorch에 붙여서 사용하실 수 있고, 다른 Framework들은 각자 독자적인 방식을 사용하고 있습니다. 

문제는 ‘자동’이 아니라서 NVIDIA에서 Framework의 종류 별로 사용방법을 정리해 놨었습니다. https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html#training_pytorch
하지만 코드를 관리하기 번거롭기 때문에 APEX로 필요한 코드들이 묶여서 나온 것입니다.

FP16을 지원하는 GPU에서 모두 사용할 수 있으며(V100, P100, Titan V), TensorCore를 이용할 수 있다면 HW 가속을 통해 ResNet-50 모델 기준으로 P100 대비 3배의 성능을 낼 수 있게 됩니다. 같은 Volta여도 두배가량 성능이 향상됩니다. 한편 GPU에 저장하는 파라미터의 크기가 절반 정도로 줄어들어 모델의 크기를 키우거나 Batch 사이즈를 늘릴 수 있게 됩니다.

CNN, RNN 그리고 multi-gpu 활용에 대한 APEX 활용 예제가 아래 링크에 올라와 있습니다.
https://github.com/NVIDIA/apex/tree/master/examples

이것을 활용하시는 방법으로는 위 예제 코드에서 fp16 또는 apex라는 키워드로 APEX 적용을 위해 추가된 부분을 여러분의 모델에 적용하시면 됩니다.
필요한 부분은 요약하자면...
1) 모델 크기를 반으로 줄이기 - network_to_half(model)
2) 입력 데이터 Precision 변환
3) FP16으로 inference (feat. TensorCore)
4) loss scaling (특정 값으로 곱하기)
5) FP16으로 back-propagation
6) gradient를 scaling했던 값으로 나누기
7) (Optioinal) Gradient Clipping
8) FP32로 Master Weight를 업데이트

https://github.com/NVIDIA/apex/tree/master/apex/amp


http://on-demand.gputechconf.com/gtc/2018/video/S8923/
http://on-demand.gputechconf.com/gtc/2018/video/S81012/


https://nvidia.github.io/apex/fp16_utils.html

