---
layout: post
title:  .
date:   2023-01-01 16:40:16
description: .
tags:
categories: cuda programming, parallel programming, performance
taxonomy:
published: false
---

https://www.anyscale.com/blog/continuous-batching-llm-inference

LLM ㅑㅜㄹㄷㄱㄷ
https://github.com/nvidia/FasterTransformer
https://github.com/triton-inference-server/pytriton
https://github.com/huggingface/text-generation-inference
https://github.com/vllm-project/vllm
https://github.com/ggerganov/ggml
https://github.com/ggerganov/llama.cpp