<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>EXPERIENTIA DOCET</title>
    <description>hanjack
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 31 Dec 2017 00:40:40 +0900</pubDate>
    <lastBuildDate>Sun, 31 Dec 2017 00:40:40 +0900</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Docker를 활용한 deep learning 개발 환경 구축</title>
        <description>&lt;p&gt;&lt;em&gt;일전에 작성하였던 &lt;a href=&quot;&quot;&gt;nvidia-docker를 활용한 deep learning 환경 구축&lt;/a&gt;이란 글이 있지만, 나의 사용방법도 변화하였고 nvidia-docker 2.0이 나왔기에 새로 작성하게 되었다. (이전 글은 내려놨다…)&lt;/em&gt;&lt;/p&gt; &lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt; &lt;p&gt;일단은 docker를 이용하는지에 대해선 이 글을 보시는 분들은 docker의 장점을 이미 알고 계실 것이라 생각하고 생각하려 한다. 아니면 docker를 쓰면 좋다는 이야기를 듣고 알아보고자 하시는 것이리라.&lt;/p&gt; &lt;p&gt;이 글은 간단한 Tutorial을 통해서 GPU가 구동되는 Deep Learning Framework을 구동하는 것이 이 글의 목표이다. 이후에 어떤 Customizing을 할 수 있는지는 별도의 글을 통해서 제공할 것이다. 다만 어떤 방향으로 이를 활용할 수 있는지는 글의 끝머리에 간단히 이야기해보려 한다.&lt;/p&gt; &lt;p&gt;여기서는 &lt;em&gt;nvidia-docker&lt;/em&gt;와 &lt;em&gt;NGC&lt;/em&gt;를 설명할 것인데, 이는 내가 생각하기에 바로 가져다 쓰는...</description>
        <pubDate>Fri, 01 Dec 2017 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/docker/2017/12/01/nvidia-docker-ngc.html</link>
        <guid isPermaLink="true">http://localhost:4000/docker/2017/12/01/nvidia-docker-ngc.html</guid>
        
        <category>docker</category>
        
        <category>nvidia-docker</category>
        
        <category>NGC</category>
        
        <category>NVIDIA</category>
        
        
        <category>docker</category>
        
      </item>
    
      <item>
        <title>CUDA GPU 메모리</title>
        <description>&lt;p&gt;GPU에서 동작하는 메모리의 종류 및 활용 방법에 대해서 알아보도록 하겠습니다. 이 포스트는 다음과 같은 것들을 다룰 예정입니다.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#device memory&quot;&gt;Device 메모리&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#shared memory&quot;&gt;Shared 메모리&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#constant memory&quot;&gt;Constant 메모리&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#texture memory&quot;&gt;Texture &amp;amp; Surface 메모리&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a id=&quot;device memory&quot; class=&quot;anckor&quot;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h1 id=&quot;device-메모리&quot;&gt;Device 메모리&lt;/h1&gt; &lt;p&gt;CUDA의 메모리에 대해서 알아보기 전, 먼저 CUDA가 동작하는 환경에 대해서 간략히 짚어보도록 하겠습니다. 앞으로 개발할 환경은 HC(Heterogeneous Computing)또는 HPC(Heterogeneous Processor Computing)라고 불리는, 한가지 이상의 프로세서를 이용하여 컴퓨팅을 이용한 환경입니다. 이는 보통의 프로그램을 개발하는 것과 독립된 동작 환경을 갖고 있는 임베디드 프로그래밍하고는 또 다른 형태의 프로그래밍 개념인데, 보조 연산 프로세서가 있다고 생각하시면 됩니다. 아래 그림을 보고 설명...</description>
        <pubDate>Sun, 10 Apr 2016 13:18:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/04/10/host-device-memory.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/04/10/host-device-memory.html</guid>
        
        <category>CUDA Programming</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>CUDA 프로세서에 대한 이해</title>
        <description>&lt;p&gt;지난 CUDA 프로그래밍 포스트에서는 CUDA 프로그래맹 모델에 대하여 이야기 해보았습니다.&lt;/p&gt; &lt;p&gt;이번에는 아래와 같은 주제로 보다 자세히 CUDA 프로그래밍에 대해 알아보도록 하겠습니다.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#CUDA Processor Architecture&quot;&gt;CUDA Processor 구조&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#CUDA Processor &amp;amp; Thread&quot;&gt;CUDA Thread Hierachy와 CUDA Processor간의 관계&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#CUDA Thread Index&quot;&gt;CUDA Thread Index 구성&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;맨 마지막 내용이 결론이므로, 컴퓨터 구조에 대한 흥미가 없으시거나 바쁘신 분들은 마지막 내용만 보고 복사해 가셔도 됩니다. 나중에 더 공부하고 싶을때 보셔도 됩니다.&lt;/p&gt; &lt;p&gt;&lt;a id=&quot;CUDA Processor Architecture&quot;&gt;&lt;/a&gt;&lt;/p&gt; &lt;h1 id=&quot;cuda-processor-구조&quot;&gt;CUDA Processor 구조&lt;/h1&gt; &lt;p&gt;CUDA Processor의 구조를 살펴보도록 하겠습니다. 그리고 어떻게 CUDA에서 병렬처리가 이뤄지는지 살펴보도록 하겠습니다.&lt;/p&gt; &lt;p&gt;&lt;img class=&quot;col three&quot; src=&quot;/images/201603/blockdiagram_big.png&quot; /&gt;&lt;/p&gt; &lt;div class=&quot;col three caption&quot;&gt; Kepler Core...</description>
        <pubDate>Thu, 31 Mar 2016 10:00:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/03/31/cuda-processor.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/03/31/cuda-processor.html</guid>
        
        <category>CUDA Programming</category>
        
        <category>CUDA Architecture</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>CUDA 프로그래밍 모델</title>
        <description>&lt;p&gt;CUDA 프로그래밍을 하면서 제가 겪었던, 또는 주위에 CUDA 프로그래밍을 주변에 소개하면서 겪었던 가장 큰 어려움은 CUDA 프로그래밍의 개념을 이해하거나 이해시키는 일이었습니다.&lt;/p&gt; &lt;p&gt;일반적인 병렬처리 기법으로 많이 사용하는 멀티쓰레드나 멀티프로세싱, 그리고 그것들의 온전한 동작을 위해 운영체제에서 제공하는 다양한 도구들은 그나마 개념적으로나마 이해할 수 있었지만, CUDA는 아무래도 다른 하드웨어에서 다른 동작 조건을 갖고 동작하기 때문인 것 같습니다. 서너개의 병렬처리를 상상하기도 벅찬데 수백개의 멀티쓰레딩을 할 수 있다는 것은 장점으로 느껴지다가도 다시 한번 생각하면, 그걸 어떻게 하는 건지 겁이 나는 것도 사실입니다.&lt;/p&gt; &lt;p&gt;때문에 CUDA Programming Model은 CUDA 프로그래밍을 하는데 있어서 중요한 개념을 제공해 줍니다.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;#SIMT&quot;&gt;CUDA Processing 모델 (SIMT Architecture)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;#Kernels&quot;&gt;CUDA Kernels&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a...</description>
        <pubDate>Sun, 27 Mar 2016 10:00:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/03/27/cuda-prog-model.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/03/27/cuda-prog-model.html</guid>
        
        <category>CUDA Programming</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>Jupyter 노트북 테마적용</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://jupyter.org&quot;&gt;Jupyter&lt;/a&gt;의 테마는 원래 하얀 색이다. &lt;img class=&quot;col&quot; src=&quot;http://jupyter.org/assets/jupyterpreview.png&quot; /&gt; &lt;!-- ![Jupyter 홈페이지에서 볼 수 있는 Jupyter의 기본 화면](http://jupyter.org/assets/jupyterpreview.png) --&gt;&lt;/p&gt; &lt;p&gt;코딩이 가능하면서도 문서와 같은 분위기여서 사용하는데 큰 무리 없이 사용할 수 있다. 하지만 모든 것(터미널 에디터 등)을 검은 화면으로 사용하는 나에게 하얀 화면은 너무 눈이 부셔서 어쩔 수 없이 보다 어두운 색으로 바꾸고 싶다는 생각이 들었다.&lt;/p&gt; &lt;p&gt;검색을 해보니 다음과 같은 github repository가 나왔다.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/nsonnad/base16-ipython-notebook&quot;&gt;42 Jupyter theme&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/dunovank/jupyter-themes&quot;&gt;3 Jupyter-themes&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;두 가지를 모두 해보았는데, 최종적으로는 dunovank의 theme가 설치도 쉽고 색상 등에 있어서 더 가독성이 좋다는 생각이 들었다.&lt;/p&gt; &lt;h2 id=&quot;설치&quot;&gt;설치&lt;/h2&gt; &lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;pip install git+https://github.com/dunovank/jupyter-themes.git&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt; &lt;p&gt;그러면 &lt;strong&gt;jupyter-theme&lt;/strong&gt;가 설치되고...</description>
        <pubDate>Tue, 08 Mar 2016 09:20:00 +0900</pubDate>
        <link>http://localhost:4000/tool/2016/03/08/jupyter-theme.html</link>
        <guid isPermaLink="true">http://localhost:4000/tool/2016/03/08/jupyter-theme.html</guid>
        
        <category>Jupyter</category>
        
        
        <category>Tool</category>
        
      </item>
    
      <item>
        <title>Jupyter 환경 구성</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://jupyter.org&quot;&gt;Jupyter&lt;/a&gt;는 웹 브라우저를 기반으로 상호작용이 가능한 프로그래밍을 할 수 있는 환경을 제공한다. 즉, 기존의 대부분의 프로그래밍 방식이 ‘편집-컴파일-실행’의 순서로 개발을 해왔다면, ‘실행-확인’으로 프로그래밍 절차를 바꿔준다. Jupyter를 이용한 개발 환경은 완전히 독립적인 프로그램을 개발하기 전에, 알고리즘을 개발하거나 데이터 분석 등 하나의 기능을 개발하는데 생산성을 높여준다. 특히 이미지, 그래프, 출력화면 등을 코드와 같이 화면에 보여주므로 그 자체 만으로도 충분한 문서가 된다.&lt;/p&gt; &lt;p&gt;Jupyter는 ipython에서 출발한 프로젝트이며, Jupyter는 ipython 4.0이후의 버전을 의미한다. 하지만 ipython이라는 이름을 버리고, juptyer라는 이름을 변경할 정도로 큰 변화가 있었는데, 그것은 다양한 언어를 지원할 수 있게 되었다는 점이다. Jupyter로 하여금 어떤 언어를 지원하고자 한다면 개발 환경과 함께 kernel을 설치 해야만...</description>
        <pubDate>Tue, 08 Mar 2016 09:10:00 +0900</pubDate>
        <link>http://localhost:4000/tool/2016/03/08/jupyter.html</link>
        <guid isPermaLink="true">http://localhost:4000/tool/2016/03/08/jupyter.html</guid>
        
        <category>Jupyter</category>
        
        
        <category>Tool</category>
        
      </item>
    
      <item>
        <title>PyCUDA</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://pypi.python.org/pypi/pycuda&quot;&gt;PyCUDA&lt;/a&gt;는 CUDA 가속을 Python 프로그램에서도 활용할 수 있도록 하기 위해서 만들어진 Python library이다. PyCUDA는 Python을 위한 CUDA Wrapper와 같은 것으로, Python으로 변형된 CUDA 프로그래밍 언어가 아니다. Python에서 CUDA를 이용하려면, 일반 C 모듈을 로딩하는 것과 같이 모듈화 부터 시작해주어야 하지만, PyCUDA를 이용한다면 그런 복잡한 절차 없이 곧바로 CUDA 프로그래밍을 할 수게 된다. 다만 CUDA C는 공부해야만 한다. [&lt;a href=&quot;https://documen.tician.de/pycuda/&quot;&gt;Document&lt;/a&gt;]&lt;/p&gt; &lt;h3 id=&quot;설치&quot;&gt;설치&lt;/h3&gt; &lt;h4 id=&quot;pycuda-다운로드&quot;&gt;PyCUDA 다운로드&lt;/h4&gt; &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone --recursive http://git.tiker.net/trees/pycuda.git cd pycuda &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;또는&lt;/p&gt; &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://pypi.python.org/packages/source/p/pycuda/pycuda-2015.1.3.tar.gz tar -xzvf pycuda-2015.1.3.tar.gz cd pycuda &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.boost.org/&quot;&gt;Boost&lt;/a&gt; - &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install libboost-all-dev&lt;/code&gt;&lt;/li&gt; &lt;li&gt;CUDA&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://numpy.org/&quot;&gt;Numpy&lt;/a&gt; - &lt;code...</description>
        <pubDate>Mon, 29 Feb 2016 09:10:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/02/29/PyCUDA.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/02/29/PyCUDA.html</guid>
        
        <category>CUDA Programming</category>
        
        <category>Python</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>Ubuntu에 CUDA 설치</title>
        <description>&lt;p&gt;우분투와 nVidia 그래픽 카드가 설치되어 있는 환경에서 진행한다.&lt;/p&gt; &lt;p&gt;CUDA Toolkit Document에 있는 &lt;a href=&quot;http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz41VsznO2m&quot;&gt;Installation Guide Linux&lt;/a&gt;에 따른다.&lt;/p&gt; &lt;h3 id=&quot;사전-설치-작업&quot;&gt;사전 설치 작업&lt;/h3&gt; &lt;h4 id=&quot;우분투-버전-확인&quot;&gt;우분투 버전 확인&lt;/h4&gt; &lt;p&gt;CUDA 7.5버전을 위해서는 Ubuntu 14.04가 최소 버전이다. 이는 이 글을 쓰고 있는 현재 LTS버전으로 배포되고 있는 버전이다. 또한 64-bit 버전이어야 한다. 혹시나 어떤 bit를 설치했는지 확인을 하고 싶다면 다음과 같은 명령어를 입력하면 확인할 수 있다. i386이 나오면 x86, amd64가 나온다면 64bit이다.&lt;/p&gt; &lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;dpkg &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; libc6 | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;Arch&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt; &lt;h4 id=&quot;cuda-카드-지원확인&quot;&gt;CUDA 카드 지원확인&lt;/h4&gt; &lt;p&gt;다음의 명령을 통해 인식된 카드의 이름 &lt;a href=&quot;http://developer.nvidia.com/cuda-gpus&quot;&gt;CUDA 지원 목록&lt;/a&gt;에도 나온다면 CUDA 프로그래밍이 가능한 카드이다.&lt;/p&gt; &lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;lspci...</description>
        <pubDate>Mon, 29 Feb 2016 09:00:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/02/29/cuda-linux.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/02/29/cuda-linux.html</guid>
        
        <category>CUDA 7.5</category>
        
        <category>CUDA Driver</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>CUDA Programming 기초</title>
        <description>&lt;h3 id=&quot;cuda-프로그래밍의-시작&quot;&gt;CUDA 프로그래밍의 시작&lt;/h3&gt; &lt;p&gt;CUDA 프로그래밍의 개념을 접할 수 있도록 간단하게 CUDA 프로그램을 만들어보도록 하겠습니다. 수행할 내용은 다음과 같습니다.&lt;/p&gt; &lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#define BUF_SIZE 100 &lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 메모리 초기화 &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUF_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUF_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUF_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 데이터 초기화 &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BUF_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span...</description>
        <pubDate>Fri, 26 Feb 2016 13:18:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/02/26/CUDA.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/02/26/CUDA.html</guid>
        
        <category>CUDA Programming</category>
        
        
        <category>CUDA</category>
        
      </item>
    
      <item>
        <title>GPGPU와 CUDA</title>
        <description>&lt;h3 id=&quot;cpu-vs-gpu-그리고-gpgpu&quot;&gt;CPU vs GPU, 그리고 GPGPU&lt;/h3&gt; &lt;h4 id=&quot;cpu와-gpu의-성능-비교&quot;&gt;CPU와 GPU의 성능 비교&lt;/h4&gt; &lt;p&gt;일반적으로 Computer에서 연산을 처리하는 모듈은 프로그램의 실행 및 시스템 자원의 관리 등에 특화 되어 있는 CPU와 영상처리를 위한 GPU로 구성되어 있습니다. 이중에서 GPU라는 것은 흔히 그래픽 카드라고 불리는 확장카드에 있는 코어를 말합니다. 과거에는 별도의 카드를 통해서 설치를 해야 했지만, 요즘은 칩 접적기술이 발달하게 되면서 대부분의 컴퓨터에서는 Mainboard에 함께 집적된 상태로 또는 CPU와 같은 칩셋에 집적된 상태로 판매되고 있습니다.&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/images//insidelogo.jpg&quot; alt=&quot;상황이 이렇다보니 2014년 당시 그래픽 칩셋의 점유율 자체는 인텔이 가장 높습니다.&quot; /&gt;&lt;/p&gt; &lt;p&gt;하지만 이러한 그래픽 칩셋들은 어디까지나 일반적인 사용환경(오피스, 웹서핑, 영화 등)에 초점을 맞춘 그래픽 카드를 포함한 것이고, 게임을...</description>
        <pubDate>Fri, 26 Feb 2016 11:18:00 +0900</pubDate>
        <link>http://localhost:4000/cuda/2016/02/26/gpgpu-cuda.html</link>
        <guid isPermaLink="true">http://localhost:4000/cuda/2016/02/26/gpgpu-cuda.html</guid>
        
        <category>CUDA Architecture</category>
        
        <category>GPGPU</category>
        
        
        <category>CUDA</category>
        
      </item>
    
  </channel>
</rss>
