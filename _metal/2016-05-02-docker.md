---
layout: post
title:  "Docker를 이용한 Deep Learning 환경 구성"
date:   2016-05-2 0:10:00
categories: Deep Learning
description: Docker를 이용한 Deep Learning 환경 구성
tags:
- Docker
- CUDA
---

Docker를 기반으로 Deep Learning 환경을 구축해보자.

Docker를 이용하여 개발 환경을 구성할 경우, 전체 시스템에서 개발 환경을 분리해서 관리할 수 있고, 필요할 경우 다른 장비로 옮기거나 다른 이들과 개발환경을 공유하는 것이 가능하다는 이점이 있다. 실제로 Udacity의 Deep Learning 강좌의 경우 강의에 사용하는 Tensorflow가 설치된 docker container를 배포하고 있어서, 학생들로 하여금 개발환경 구축에 대한 부담없이 Deep Learning을 시작할 수 있도록 도와주고 있다. 개인적으로는 개발 환경과 작업하고 있는 source code를 분리해서 관리하고, 개발 환경을 정리하는 용도로 활용하고 있다.

여기서는 Docker가 무엇이고, 어떻게 사용한다고 하기 보다는, 내가 사용하는 Docker에 대한 사례를 소개하는 것을 중점으로 한다.

먼저 Deep Learning을 위해서 CUDA가 설치된 Linux 환경을 이용할 것이다. 없다면 CUDA가 가능한 container를 가져오는 절차를 건너뛰어도 무방하다. Linux에서 CUDA 환경이 구축되지 않았다면, [Linux 환경에서 CUDA 개발환경 구축](/cuda/2016-02-29-cuda-linux/) 문서를 참조하자.

# Docker 설치 (Debian/Ubuntu)

[Docker Document](https://docs.docker.com/engine/installation/linux/debian/)에 있는 것을 참조하였다. 다른 리눅스 버전이라도 링크된 문서를 따라가 해당 내용을 참고하면 된다.

## Repository Update

Docker Repository를 등록한다.
{% highlight bash %}
$ apt-get update
$ apt-get install apt-trasport-https ca-certificate
$ apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
{% endhighlight %}

debian 8.0 (jessie)라면 다음과 같이 쉘에 입력한다. 다른 버전에 대해서는 *debian-jessie* 외에 다른 배포한 및 버전을 지정해 주어야 한다.
{% highlight bash %}
$ sudo echo 'deb https://apt.dockerproject.org/repo debian-jessie main' > /etc/apt/sources.list.d/docker/list
{% endhighlight %}

이후 Repository를 업데이트 한다.
{% highlight bash %}
$ sudo apt-get update && sudo apt-get upgrade
{% endhighlight %}

## Docker 설치

{% highlight bash %}
$ sudo apt-get install docker-engine
{% endhighlight %}

Docker를 사용하기 위해서는 항상 **root**이어야만 한다. 하지만 docker group을 추가하고, group내 user를 추가함으로서 root가 아니어도 docker를 사용할 수 있도록 할 수 있다.

{% highlight bash %}
$ sudo groupadd docker
$ sudo gpasswd -a $(USER) docker
$ sudo service docker restart
{% endhighlight %}

# NVIDIA CUDA 이미지 설치

## Dockerfile 구성

Docker에서 CUDA를 이용하기 위해서는, Base가 되는 Linux 시스템 뿐만 아니라 Docker Image에서도 CUDA를 사용할 수 있어야 한다. Docker에서 CUDA를 사용할 수 있는 Dockerfile은 NVIDIA에서 공개한 [NVIDIA Docker](https://github.com/NVIDIA/nvidia-docker)를 사용할 것이므로, 큰 어려움 없이 Image를 구성할 수 있다.

{% highlight bash %}
# Repository clone
$ git clone https://github.com/NVIDIA/nvidia-docker
{% endhighlight %}

다만 몇가지 변경을 해주어야 하는데 githum에 있는 데로 하면, 이 글을 쓰고 있는 날짜 기준(2016년 5월 2일)으로 지원하지 않는 docker 버전이라고 나온다. 여하튼 Debian 배포판을 이용하는, CUDA가 가능한 docker image를 만들기 위해 Repository를 받아서 다음과 같이 수정을 하였다.

만약 ubuntu를 그대로 이용하겠다면 다음 내용을 건너뛰고 Image Build로 넘어가면 된다.

## Debian 기반 Dockerfile build 환경 구성

{% highlight bash %}
# Ubuntu를 기준으로 Debian 기반 Dockerfile을 구성한다.
$ cp -R ubuntu-14.04 debian

# Debian으로 OS 변경
$ cd nvidia-docker
$ find ./debian -name "Dockerfile" -exec perl -pi -e 's/ubuntu:14.04/debian:latest/g' {} \;
{% endhighlight %}

## Docker Image 빌드

**nvidia-docker** 디렉토리에서 진행한다.

{% highlight bash %}
$ de debian/cuda
$ make 7.5-cudnn4-devel
{% endhighlight %}

선택가능한 옵션이 많지만, 여기서는 **cuda 7.5-devel-cudnn4**로 하였다.
Makefile의 의존관계를 살펴보면 알겠지만, 위 옵션을 선택하는 경우, CUDA 7.5-runtime > devel > cudnn4 순으로 빌드가 이뤄진다. Dockerfile를 컴파일하는데 make가 사용되는 이유는 전적으로 Dockerfile이 include를 지원하지 않기 때문이다. 앞으로도 docker는 Dockerfile 내에 Dockerfile을 include 하지 않을 것이라 한다.

build가 완료된다면 의존관계에 따라 복수의 image가 생성되는 것을 확인할 수 있다.
<img class="col three" src="/images/201605/Docker%20images.png"/>

## Docker Image 실행

내가 선호하는 Docker image의 실행구성은 다음과 같다.

<img class="col two center" src="/images/201605/Docker&Linux.png"/>

즉, Docker Container 내에 내가 작성한 Code를 저장하지 않도록 하는 것이다. 이렇게 하였을 때 몇가지 이득이 있다.

1. Docker Container를 언제든지 종료할 수 있다.
1. Docker를 실행하지 않고 Source Code에 접근할 수 있다.
1. SouceCode와 Cloud 서비스를 연동하여 파일을 외부에서 자유롭게 관리할 수 있다.
1. 어떤 Container에 파일을 작업했었는지 찾을 필요가 없다.

다른 더 좋은 구성이 있으면 따르겠지만 현재 내가 하는 선에서는 이것이 최선으로 보인다.

이러한 방법으로 실행하기 위해서 **-v** docker option을 사용한다. **-v** 옵션은 docker를 실행할 때 지정된 directory와 image 내의 지정된 dicectory를 공유 공간으로 하여 양쪽에서 접근 및 수정을 가능하게 해준다.

실제 내가 사용하는 명령은 다음과 같다. 각 부분에 대한 설명은 개발 환경 구성까지 마친 후 상세히 설명할 것이다.

{% highlight bash %}
docker run -p 8888:8888 -it -v "$(pwd):/workspace" --rm metal/ml /bin/zsh
{% endhighlight %}

# 개발 환경 구성

드디어 Deep Learning을 시험해 볼 수 있는 개발환경을 구축하는 단계로 왔다.

첨부된 Dockerfile은 크게 다음과 같은 구성을 갖고 있다.

1. Python2, Python3, Octave 설치
1. 개발 환경 설치 (build-essential, git, vim, wget, curl, lapack, blas 등등)
1. pandas, pip, cython, scikit_learn, jupyter 등 설치
1. jupyter 실행 script 추가, jupyter kernel 설치, jupyter 테마 설치
1. zsh 설치

파일의 내용은 다음을 참고한다.
[Dockerfile]()
[notebook.sh]()

위 두 파일을 동일한 경로에 위치시키고, 다음과 같시 dockerfile을 build 한다. image의 이름은 원하는 아무 이름을 써도 무방하다.

{% highlight bash %}
docker build -t metal/default .
{% endhighlight %}

### Docker 실행

컴파일이 완료되었다면 정상적으로 jupyter를 포함한 설치한 개발 환경이 잘 동작하는지 확인해보자.

{% highlight bash %}
$ docker run -p 8888:8888 -it -v "$(pwd):/workspace" --rm metal/default /bin/zsh

# Docker 내부에서 실행
$ /notebook.sh
{% endhighlight %}

docker 명령어의 풀이는 다음과 같다.

| docker run | -p 8888:8888 |-it | -v "$(pwd):/workspace" | --rm metal/default | /bin/zsh |
| image 실행 | jupyter에서 사용할 8888 포트 공개 | interactive mode | 현재 경로를 docker container의 /workspace에 동기화 | metal/default 이미지 참조 | zsh를 기본 프로그램으로 실행 |

<br/>

# Deep Learning Libary 설치
이제 Deep Learning Library인 Theano와 Tensorflow를 설치해보자.

### Dockerfile 생성

아래와 같이 Dockerfile을 생성한다.

{% highlight bash %}
FROM metal/default

# install tensorflow
RUN aptitude install curl --without-recommends &&\
    curl -O https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl &&\
    pip install --upgrade tensorflow-0.8.0-cp27-none-linux_x86_64.whl &&\
    rm tensorflow-0.8.0-cp27-none-linux_x86_64.whl &&\
    pip install -U scikit-learn

# install theano
RUN aptitude install liblapack-dev libblas-dev gfortran --without-recommends -y &&\
    pip install --upgrade git+git://github.com/Theano/Theano.git &&\
    theano-nose
{% endhighlight %}

### Docker image 빌드 및 실행

{% highlight bash %}
# 빌드
$ docker build -t metal/ml .

# 실행
$ docker run -p 8888:8888 -it -v "$(pwd):/workspace" --rm metal/dl /bin/zsh
{% endhighlight %}

각 라이브러리의 예제를 가져와서 실행해보면 잘 동작 할 것이다.